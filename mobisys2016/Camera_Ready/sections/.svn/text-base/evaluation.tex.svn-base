\mysection{Implementation and Evaluation}
\label{section:evaluation}

We implemented our policy enforcement mechanism on a i.MX53 Quick Start Board
from Freescale as our guest device. This board is TrustZone-enabled and has a
1GHz ARM Cortex A8 processor with 1GB DDR3 RAM. We chose this board as the
guest device because it offers open, programmable access to the secure world.
In contrast, the vendors of most commercially-available TrustZone-enabled
devices today lock down the secure world and prevent any modifications to it. A
small part of main memory is reserved for exclusive use by the secure world. On
our i.MX53 board, we assigned the secure world 256MB of memory, although it may
be possible to reduce this with future optimizations. The normal world runs
Android 2.3.4 atop Linux kernel version 2.6.35.3.

We built a bare-metal runtime environment for the secure world, just enough to
support the components shown in \figref{figure:overall}. This environment has a
memory manager, and a handler to parse and process commands received from the
host via the normal world. To implement cryptographic operations, we used
components from an off-the-shelf library called the ARM mbed TLS
(v1.3.9)~\cite{polarssl}.  Excluding the cryptography library, our secure world
consists of about 3,500 lines of C code, including about 250 lines of inline
assembly.  
%
\addtext{Task 6}{The secure world implements all the features described in
\sectref{section:mechanism}, except for one minor deviation in the
implementation of the REM-suspend protocol. The i.MX53 does not support \kdev,
so our prototype implements REM-suspend assuming that such a key is available
and can be fetched from hardware.}

\figref{table:loc} shows the sizes of various components.  We used mbed TLS's
implementation of SHA1 and HMACs, RSA and X509 certificates.  As shown in
\figref{table:loc}, the files implementing these components alone comprise only
about 4,000 lines of code. In addition to these secure world components, we
built the kernel module and the UI app (written as a native daemon) for the
normal world, comprising 165 lines of code.  We implemented a host policy
server that authenticates guest devices, and performs remote memory operations.
We conducted experiments to showcase the utility of remote reads and writes to
enforce the host's policies on the guest. The guest and the host communicate
over WiFi.
%
% Host's policy server: 1756 (plus 48LOC of python for memory analysis). 

\myparagraph{Guest Device Analysis}
%
To illustrate the power of remote memory read operations to perform device
analysis, we wrote a simple rootkit that infects the guest's normal world
kernel by hooking its system call table. In particular, it replaces the entry
for the \textsf{close} system call to instead point to a malicious function
injected into the kernel. The malicious functionality ensures that if the
process invoking \textsf{close} calls it with a magic number, then the process
is elevated to \textsf{root}.  Although simple in its operation, Petroni and
Hicks~\cite{sbcfi:ccs07} show that over 95\% of all rootkits that modify kernel
data operate this way.

We were able to detect this rootkit on the host by remotely reading and
analyzing the guest's memory pages. We remotely read pages containing the
\textsf{init}, \textsf{text} and \textsf{data} sections of kernel memory. Our
analyzer, a 48 line Python script, reads the addresses in the system call table
from memory, and compares these entries with addresses in \textsf{System.map}.
If the address is not included, \eg~as happens if the entry for the
\textsf{close} system call is modified, it raises an error. For more
sophisticated rootkits that modify arbitrary kernel data structures, the host
can use complex detection algorithms~\cite{sbcfi:ccs07,gib:tdsc11,kop:ccs09}
based on the recursive snapshot traversal method outlined in
\sectref{section:policy}.

For the above experiment, it took the secure world 54 seconds to create an HMAC
over the memory pages that were sent to the host (9.2MB in total). It takes
under a second to copy data from the normal world to the secure world and vice
versa. It may be possible to accelerate the performance of the HMAC
implementation using floating point registers and hardware acceleration, but we
have not done so in our prototype.

\input{sections/robustness-table}

\myparagraph{Guest Device Control}
%
We evaluated the host's ability to dynamically reconfigure a guest device via
remote memory write operations. For this experiment, we attempted to disable a
number of peripherals from the guest device. However, the i.MX53 board only
supports a bare-minimum number of peripherals. As proof-of-concept, we
therefore tested the effectiveness of remote writes on a Samsung Galaxy Nexus
smart phone with a Texas Instruments OMAP 4460 chipset. This chipset has a
1.2GHz dual-core ARM Cortex-A9 processor with 1GB of RAM, and runs Android 4.3
atop Linux kernel version 3.0.72. This device has a rich set of peripherals,
but its chipset comes with TrustZone locked down, \ie~the secure world is not
accessible to third-party programmers.  We therefore performed remote writes by
modifying memory using a kernel module in its (normal world) OS.  Thus, while
remote writes to this device do not enjoy the security properties described in
\sectref{section:mechanism}, they allow us to evaluate the ability to uninstall
a variety of peripherals from a running guest device.

\figref{table:uninstall} shows the set of peripherals that we uninstalled, the
method used to uninstall the peripheral (from \sectref{section:policy}), the
device on which we performed the operation (i.MX53 or Nexus), and the size of
the write operation, \ie~the number of bytes that we had to modify/introduce in
the kernel.  We were able to uninstall the USB on the i.MX53 and the camera on
the phone by \textsc{null}ifying the peripheral interface. For other
peripherals, we introduced dummy drivers designed according to the safety
criterion from \sectref{section:vetting}. We also used dummy drivers for the
USB and the camera to compare the size of the write operations. In this case,
the size of the write includes both the bytes modified in the peripheral
interface and the dummy driver functions. For the 3G interface, we considered
two cases: that of disabling only 3G data and that of only disabling calls. Our
experiment shows it is possible to uninstall peripherals without crashing the
OS by just modifying a few hundred bytes of memory on the running device. 

\addtext{Tasks 1\&3}{For each uninstalled peripheral, \figref{table:uninstall}
shows the time taken by the vetting service to determine the safety of the
write operation (using the policy from \sectref{section:vetting}). Our vetting
service runs on a quad-core Intel i5-4960 CPU running at 3.5Gz, with 16GB of
memory.  \figref{table:uninstall} also shows the size of the verification token
generated by the secure world for the write operation. The size of the
verification token grows linearly with the size of the write operation, but is
just a few hundred bytes in all cases. On the i.MX53, it took the secure world
under 6 milliseconds to generate the verification tokens. This shows that it is
practical for the host to request the guest device to resend the verification
token at periodic intervals during its stay in the restricted space.}

Installing a dummy driver disables the peripheral, but how does it affect the
user app that is using the peripheral? To answer this question, we conducted
two sets of experiments involving a number of client user apps that leverage
the peripherals shown in \figref{table:uninstall}.  In the first set of
experiments, which we call the \textit{passive setting}, we start with a
configuration where the client app is not executing, replace the device driver
of the peripheral with a dummy, and then start the app. In the second set of
experiments, called the \textit{active setting}, we replace the peripheral's
device driver with the dummy as the client app that uses the peripheral is
executing. 

\figref{table:robustness} shows the results of our experiments. For both the
passive and active settings, we observe that in most cases, the user app
displays a suitable error message or changes its behavior by displaying a blank
screen or creating an empty audio file. In some cases, particularly in the
passive setting, the app fails to start when the driver is replaced, and the
Android runtime displays an error that it is unable to start the app.

